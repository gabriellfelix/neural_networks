{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1c9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1dd58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.felix\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importando o Dataset\n",
    " \n",
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14621811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo as chaves da dict 'boston_dataset'\n",
    "\n",
    "boston_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3385312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Dataset:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando o dataset com o Pandas\n",
    "\n",
    "display(Markdown(\"**Dataset:**\"))\n",
    "boston_x = pd.DataFrame(data=boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9afc542f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Variável Target:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregando a variável target do dataset com o Pandas\n",
    "\n",
    "display(Markdown(\"**Variável Target:**\"))\n",
    "boston_y = pd.DataFrame(data=boston_dataset.target, columns=['MEDV'])\n",
    "#boston_y = boston_y/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ce16bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Estatísticas descritivas do Dataset:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibindo as estatísticas descritivas do dataset\n",
    "\n",
    "display(Markdown(\"**Estatísticas descritivas do Dataset:**\"))\n",
    "boston_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f77ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13) (303, 1)\n",
      "\n",
      "(101, 13) (101, 1)\n",
      "\n",
      "(102, 13) (102, 1)\n"
     ]
    }
   ],
   "source": [
    "# Divisão do dataset em conjunto de treinamento e conjunto de teste (para variáveis independentes e variável target)\n",
    "\n",
    "x_train, x_valid_test, y_train, y_valid_test = train_test_split(boston_x, boston_y, test_size=0.4, random_state=5)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_valid_test, y_valid_test, test_size=0.5, random_state=5)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_valid = np.array(y_valid).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print()\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print()\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe09c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando a normalização min-max (coletando características min-max das features)\n",
    "\n",
    "scaler_x = MinMaxScaler().fit(x_train)\n",
    "scaler_y = MinMaxScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3501d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a normalização min-max no dataset sem a variável target\n",
    "\n",
    "x_train = scaler_x.transform(x_train)\n",
    "x_valid = scaler_x.transform(x_valid)\n",
    "x_test = scaler_x.transform(x_test)\n",
    "\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_valid = scaler_y.transform(y_valid)\n",
    "y_test = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abfae1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([303, 13]) torch.Size([303, 1])\n",
      "torch.Size([101, 13]) torch.Size([101, 1])\n",
      "torch.Size([102, 13]) torch.Size([102, 1])\n"
     ]
    }
   ],
   "source": [
    "# Transformando o array das variáveis independentes em tensores\n",
    "\n",
    "tensor_x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "tensor_y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "tensor_x_valid = torch.tensor(x_valid, dtype=torch.float32)\n",
    "tensor_y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "                             \n",
    "tensor_x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "tensor_y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "                             \n",
    "print(tensor_x_train.shape, tensor_y_train.shape)\n",
    "print(tensor_x_valid.shape, tensor_y_valid.shape)\n",
    "print(tensor_x_test.shape, tensor_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee63dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataset e o dataloader para dividir os dados de treinamento em lotes (batchs)\n",
    "\n",
    "n_batchs = 10\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x_train, tensor_y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = n_batchs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07e8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_hidden=30):\n",
    "        super(Net, self).__init__()\n",
    "        self.lr1 = nn.Linear(13, n_hidden)\n",
    "        self.dp = nn.Dropout(0.2)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.lr2 = nn.Linear(n_hidden, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.lr2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b49d6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    net = Net(config[\"n_hidden\"])\n",
    "    \n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"], weight_decay=1e-5)\n",
    "    \n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)   \n",
    "\n",
    "    for epoch in range(config[\"n_epochs\"]):\n",
    "        losses = []\n",
    "        r2_s = []\n",
    "        for x, y in config[\"train_dataloader\"]:\n",
    "        \n",
    "            pred_y = net(x.to(torch.float32))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function(pred_y, y.to(torch.float32))\n",
    "            r2 = r2_score(y.to(torch.float32), pred_y.detach().numpy())\n",
    "            r2_s.append(r2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        loss_train = np.mean(losses)\n",
    "        r2_train = np.mean(r2_s)\n",
    "            \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        pred_y = net(config[\"valid_x\"])\n",
    "\n",
    "        loss_valid = loss_function(pred_y, config[\"valid_y\"])\n",
    "        r2_valid = r2_score(config[\"valid_y\"], pred_y)\n",
    "        \n",
    "    \n",
    "    os.makedirs(\"my_model\", exist_ok=True)\n",
    "    torch.save((net.state_dict(), optimizer.state_dict()), \"my_model/checkpoint.pt\")\n",
    "    checkpoint = Checkpoint.from_directory(\"my_model\")\n",
    "\n",
    "    session.report({\"r2_train\": r2_train, \"loss_train\": loss_train, \"r2_valid\": r2_valid, \"loss_valid\": loss_valid}, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66b32c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"train_dataloader\": train_dataloader,\n",
    "    \"valid_x\": tensor_x_valid,\n",
    "    \"valid_y\": tensor_y_valid,\n",
    "    \"n_epochs\": tune.grid_search([500, 1000, 1500]),\n",
    "    \"n_hidden\": tune.grid_search([6,8,10]),\n",
    "    \"lr\": tune.grid_search([0.005,0.01,0.015])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "276e8d99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 10:51:22,979\tINFO worker.py:1519 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2022-12-16 10:51:30,460\tWARNING function_trainable.py:586 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-16 11:00:06</td></tr>\n",
       "<tr><td>Running for: </td><td>00:08:36.05        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.8/15.8 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/5.72 GiB heap, 0.0/2.86 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  n_epochs</th><th style=\"text-align: right;\">  n_hidden</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  r2_train</th><th style=\"text-align: right;\">  loss_train</th><th style=\"text-align: right;\">  r2_valid</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_be744_00000</td><td>TERMINATED</td><td>127.0.0.1:13380</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         30.5186</td><td style=\"text-align: right;\">  0.485362</td><td style=\"text-align: right;\">  0.00825777</td><td style=\"text-align: right;\">  0.806936</td></tr>\n",
       "<tr><td>train_be744_00001</td><td>TERMINATED</td><td>127.0.0.1:3500 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.8533</td><td style=\"text-align: right;\">  0.626404</td><td style=\"text-align: right;\">  0.00977164</td><td style=\"text-align: right;\">  0.764041</td></tr>\n",
       "<tr><td>train_be744_00002</td><td>TERMINATED</td><td>127.0.0.1:5720 </td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         38.9904</td><td style=\"text-align: right;\">  0.482689</td><td style=\"text-align: right;\">  0.0100346 </td><td style=\"text-align: right;\">  0.738247</td></tr>\n",
       "<tr><td>train_be744_00003</td><td>TERMINATED</td><td>127.0.0.1:756  </td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         98.5454</td><td style=\"text-align: right;\">  0.661341</td><td style=\"text-align: right;\">  0.0107808 </td><td style=\"text-align: right;\">  0.762574</td></tr>\n",
       "<tr><td>train_be744_00004</td><td>TERMINATED</td><td>127.0.0.1:12944</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        106.66  </td><td style=\"text-align: right;\">  0.633465</td><td style=\"text-align: right;\">  0.00886191</td><td style=\"text-align: right;\">  0.769352</td></tr>\n",
       "<tr><td>train_be744_00005</td><td>TERMINATED</td><td>127.0.0.1:14252</td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        111.692 </td><td style=\"text-align: right;\">  0.568311</td><td style=\"text-align: right;\">  0.00993982</td><td style=\"text-align: right;\">  0.702089</td></tr>\n",
       "<tr><td>train_be744_00006</td><td>TERMINATED</td><td>127.0.0.1:5032 </td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        186.359 </td><td style=\"text-align: right;\">  0.682036</td><td style=\"text-align: right;\">  0.00921407</td><td style=\"text-align: right;\">  0.7972  </td></tr>\n",
       "<tr><td>train_be744_00007</td><td>TERMINATED</td><td>127.0.0.1:13560</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        191.772 </td><td style=\"text-align: right;\">  0.611504</td><td style=\"text-align: right;\">  0.0101072 </td><td style=\"text-align: right;\">  0.75725 </td></tr>\n",
       "<tr><td>train_be744_00008</td><td>TERMINATED</td><td>127.0.0.1:13380</td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">         6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        180.777 </td><td style=\"text-align: right;\">  0.443318</td><td style=\"text-align: right;\">  0.0104838 </td><td style=\"text-align: right;\">  0.824645</td></tr>\n",
       "<tr><td>train_be744_00009</td><td>TERMINATED</td><td>127.0.0.1:3500 </td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         57.3237</td><td style=\"text-align: right;\">  0.718157</td><td style=\"text-align: right;\">  0.00917767</td><td style=\"text-align: right;\">  0.806815</td></tr>\n",
       "<tr><td>train_be744_00010</td><td>TERMINATED</td><td>127.0.0.1:5720 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         60.8468</td><td style=\"text-align: right;\">  0.686772</td><td style=\"text-align: right;\">  0.00949374</td><td style=\"text-align: right;\">  0.795744</td></tr>\n",
       "<tr><td>train_be744_00011</td><td>TERMINATED</td><td>127.0.0.1:756  </td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         60.1519</td><td style=\"text-align: right;\">  0.664446</td><td style=\"text-align: right;\">  0.00986921</td><td style=\"text-align: right;\">  0.818452</td></tr>\n",
       "<tr><td>train_be744_00012</td><td>TERMINATED</td><td>127.0.0.1:3500 </td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        129.955 </td><td style=\"text-align: right;\">  0.708986</td><td style=\"text-align: right;\">  0.00825787</td><td style=\"text-align: right;\">  0.779783</td></tr>\n",
       "<tr><td>train_be744_00013</td><td>TERMINATED</td><td>127.0.0.1:5720 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        130.581 </td><td style=\"text-align: right;\">  0.706976</td><td style=\"text-align: right;\">  0.00880297</td><td style=\"text-align: right;\">  0.76148 </td></tr>\n",
       "<tr><td>train_be744_00014</td><td>TERMINATED</td><td>127.0.0.1:12944</td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        123.947 </td><td style=\"text-align: right;\">  0.575121</td><td style=\"text-align: right;\">  0.00868041</td><td style=\"text-align: right;\">  0.820012</td></tr>\n",
       "<tr><td>train_be744_00015</td><td>TERMINATED</td><td>127.0.0.1:14252</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        189.137 </td><td style=\"text-align: right;\">  0.419729</td><td style=\"text-align: right;\">  0.00934356</td><td style=\"text-align: right;\">  0.789051</td></tr>\n",
       "<tr><td>train_be744_00016</td><td>TERMINATED</td><td>127.0.0.1:756  </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        189.321 </td><td style=\"text-align: right;\">  0.709179</td><td style=\"text-align: right;\">  0.00940884</td><td style=\"text-align: right;\">  0.78743 </td></tr>\n",
       "<tr><td>train_be744_00017</td><td>TERMINATED</td><td>127.0.0.1:5032 </td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">         8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        182.22  </td><td style=\"text-align: right;\">  0.601442</td><td style=\"text-align: right;\">  0.0102294 </td><td style=\"text-align: right;\">  0.783667</td></tr>\n",
       "<tr><td>train_be744_00018</td><td>TERMINATED</td><td>127.0.0.1:13380</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         59.6732</td><td style=\"text-align: right;\">  0.715514</td><td style=\"text-align: right;\">  0.00863194</td><td style=\"text-align: right;\">  0.814043</td></tr>\n",
       "<tr><td>train_be744_00019</td><td>TERMINATED</td><td>127.0.0.1:3500 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         64.5724</td><td style=\"text-align: right;\">  0.663212</td><td style=\"text-align: right;\">  0.00934981</td><td style=\"text-align: right;\">  0.799475</td></tr>\n",
       "<tr><td>train_be744_00020</td><td>TERMINATED</td><td>127.0.0.1:12944</td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">       500</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         59.12  </td><td style=\"text-align: right;\">  0.613933</td><td style=\"text-align: right;\">  0.009472  </td><td style=\"text-align: right;\">  0.732715</td></tr>\n",
       "<tr><td>train_be744_00021</td><td>TERMINATED</td><td>127.0.0.1:13560</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        128.081 </td><td style=\"text-align: right;\">  0.710137</td><td style=\"text-align: right;\">  0.00789656</td><td style=\"text-align: right;\">  0.825004</td></tr>\n",
       "<tr><td>train_be744_00022</td><td>TERMINATED</td><td>127.0.0.1:5720 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        127.383 </td><td style=\"text-align: right;\">  0.656363</td><td style=\"text-align: right;\">  0.00854754</td><td style=\"text-align: right;\">  0.812054</td></tr>\n",
       "<tr><td>train_be744_00023</td><td>TERMINATED</td><td>127.0.0.1:13380</td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">      1000</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        117.719 </td><td style=\"text-align: right;\">  0.596126</td><td style=\"text-align: right;\">  0.0083289 </td><td style=\"text-align: right;\">  0.658339</td></tr>\n",
       "<tr><td>train_be744_00024</td><td>TERMINATED</td><td>127.0.0.1:12944</td><td style=\"text-align: right;\">0.005</td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        151.756 </td><td style=\"text-align: right;\">  0.691925</td><td style=\"text-align: right;\">  0.00888146</td><td style=\"text-align: right;\">  0.812546</td></tr>\n",
       "<tr><td>train_be744_00025</td><td>TERMINATED</td><td>127.0.0.1:3500 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        149.356 </td><td style=\"text-align: right;\">  0.663007</td><td style=\"text-align: right;\">  0.00986474</td><td style=\"text-align: right;\">  0.807807</td></tr>\n",
       "<tr><td>train_be744_00026</td><td>TERMINATED</td><td>127.0.0.1:14252</td><td style=\"text-align: right;\">0.015</td><td style=\"text-align: right;\">      1500</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        137.244 </td><td style=\"text-align: right;\">  0.661779</td><td style=\"text-align: right;\">  0.0105981 </td><td style=\"text-align: right;\">  0.742547</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                        </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  loss_train</th><th style=\"text-align: right;\">  loss_valid</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  r2_train</th><th style=\"text-align: right;\">  r2_valid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_be744_00000</td><td>2022-12-16_10-52-21</td><td>True  </td><td>                </td><td>5a68b6b5002e40e78a04a2a6e8617e80</td><td>0_lr=0.0050,n_epochs=500,n_hidden=6   </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00825777</td><td style=\"text-align: right;\">  0.00927777</td><td>127.0.0.1</td><td style=\"text-align: right;\">13380</td><td style=\"text-align: right;\">  0.485362</td><td style=\"text-align: right;\">  0.806936</td><td>True               </td><td style=\"text-align: right;\">             30.5186</td><td style=\"text-align: right;\">           30.5186</td><td style=\"text-align: right;\">       30.5186</td><td style=\"text-align: right;\"> 1671198741</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00000</td><td style=\"text-align: right;\">    0        </td></tr>\n",
       "<tr><td>train_be744_00001</td><td>2022-12-16_10-52-37</td><td>True  </td><td>                </td><td>50c2d66cbadd40ee9ccf7b2bbb2c9bb7</td><td>1_lr=0.0100,n_epochs=500,n_hidden=6   </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00977164</td><td style=\"text-align: right;\">  0.0113391 </td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3500</td><td style=\"text-align: right;\">  0.626404</td><td style=\"text-align: right;\">  0.764041</td><td>True               </td><td style=\"text-align: right;\">             35.8533</td><td style=\"text-align: right;\">           35.8533</td><td style=\"text-align: right;\">       35.8533</td><td style=\"text-align: right;\"> 1671198757</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00001</td><td style=\"text-align: right;\">    0.0156081</td></tr>\n",
       "<tr><td>train_be744_00002</td><td>2022-12-16_10-52-50</td><td>True  </td><td>                </td><td>7fd1ec8b55384e28872f7c76ab57aa0c</td><td>2_lr=0.0150,n_epochs=500,n_hidden=6   </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.0100346 </td><td style=\"text-align: right;\">  0.0125787 </td><td>127.0.0.1</td><td style=\"text-align: right;\"> 5720</td><td style=\"text-align: right;\">  0.482689</td><td style=\"text-align: right;\">  0.738247</td><td>True               </td><td style=\"text-align: right;\">             38.9904</td><td style=\"text-align: right;\">           38.9904</td><td style=\"text-align: right;\">       38.9904</td><td style=\"text-align: right;\"> 1671198770</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00002</td><td style=\"text-align: right;\">    0.0156271</td></tr>\n",
       "<tr><td>train_be744_00003</td><td>2022-12-16_10-54-01</td><td>True  </td><td>                </td><td>7284666db91d4b718a8947fc3d7df709</td><td>3_lr=0.0050,n_epochs=1000,n_hidden=6  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.0107808 </td><td style=\"text-align: right;\">  0.0114096 </td><td>127.0.0.1</td><td style=\"text-align: right;\">  756</td><td style=\"text-align: right;\">  0.661341</td><td style=\"text-align: right;\">  0.762574</td><td>True               </td><td style=\"text-align: right;\">             98.5454</td><td style=\"text-align: right;\">           98.5454</td><td style=\"text-align: right;\">       98.5454</td><td style=\"text-align: right;\"> 1671198841</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00003</td><td style=\"text-align: right;\">    0.0156147</td></tr>\n",
       "<tr><td>train_be744_00004</td><td>2022-12-16_10-54-21</td><td>True  </td><td>                </td><td>1d398e6110e54e1d91969ce7424d88b4</td><td>4_lr=0.0100,n_epochs=1000,n_hidden=6  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00886191</td><td style=\"text-align: right;\">  0.0110839 </td><td>127.0.0.1</td><td style=\"text-align: right;\">12944</td><td style=\"text-align: right;\">  0.633465</td><td style=\"text-align: right;\">  0.769352</td><td>True               </td><td style=\"text-align: right;\">            106.66  </td><td style=\"text-align: right;\">          106.66  </td><td style=\"text-align: right;\">      106.66  </td><td style=\"text-align: right;\"> 1671198861</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00004</td><td style=\"text-align: right;\">    0.0156269</td></tr>\n",
       "<tr><td>train_be744_00005</td><td>2022-12-16_10-54-39</td><td>True  </td><td>                </td><td>725f5d20811b4072b253eb4b374015ad</td><td>5_lr=0.0150,n_epochs=1000,n_hidden=6  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00993982</td><td style=\"text-align: right;\">  0.0143163 </td><td>127.0.0.1</td><td style=\"text-align: right;\">14252</td><td style=\"text-align: right;\">  0.568311</td><td style=\"text-align: right;\">  0.702089</td><td>True               </td><td style=\"text-align: right;\">            111.692 </td><td style=\"text-align: right;\">          111.692 </td><td style=\"text-align: right;\">      111.692 </td><td style=\"text-align: right;\"> 1671198879</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00005</td><td style=\"text-align: right;\">    0.015625 </td></tr>\n",
       "<tr><td>train_be744_00006</td><td>2022-12-16_10-56-08</td><td>True  </td><td>                </td><td>c81df167ca754430b8add20d282b0d4a</td><td>6_lr=0.0050,n_epochs=1500,n_hidden=6  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00921407</td><td style=\"text-align: right;\">  0.00974563</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 5032</td><td style=\"text-align: right;\">  0.682036</td><td style=\"text-align: right;\">  0.7972  </td><td>True               </td><td style=\"text-align: right;\">            186.359 </td><td style=\"text-align: right;\">          186.359 </td><td style=\"text-align: right;\">      186.359 </td><td style=\"text-align: right;\"> 1671198968</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00006</td><td style=\"text-align: right;\">    0.0156186</td></tr>\n",
       "<tr><td>train_be744_00007</td><td>2022-12-16_10-56-28</td><td>True  </td><td>                </td><td>92616637421e4f1c8b1417b12a6d79ab</td><td>7_lr=0.0100,n_epochs=1500,n_hidden=6  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.0101072 </td><td style=\"text-align: right;\">  0.0116654 </td><td>127.0.0.1</td><td style=\"text-align: right;\">13560</td><td style=\"text-align: right;\">  0.611504</td><td style=\"text-align: right;\">  0.75725 </td><td>True               </td><td style=\"text-align: right;\">            191.772 </td><td style=\"text-align: right;\">          191.772 </td><td style=\"text-align: right;\">      191.772 </td><td style=\"text-align: right;\"> 1671198988</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00007</td><td style=\"text-align: right;\">    0.0156238</td></tr>\n",
       "<tr><td>train_be744_00008</td><td>2022-12-16_10-56-18</td><td>True  </td><td>                </td><td>5a68b6b5002e40e78a04a2a6e8617e80</td><td>8_lr=0.0150,n_epochs=1500,n_hidden=6  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.0104838 </td><td style=\"text-align: right;\">  0.00842675</td><td>127.0.0.1</td><td style=\"text-align: right;\">13380</td><td style=\"text-align: right;\">  0.443318</td><td style=\"text-align: right;\">  0.824645</td><td>True               </td><td style=\"text-align: right;\">            180.777 </td><td style=\"text-align: right;\">          180.777 </td><td style=\"text-align: right;\">      180.777 </td><td style=\"text-align: right;\"> 1671198978</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00008</td><td style=\"text-align: right;\">    0        </td></tr>\n",
       "<tr><td>train_be744_00009</td><td>2022-12-16_10-54-14</td><td>True  </td><td>                </td><td>50c2d66cbadd40ee9ccf7b2bbb2c9bb7</td><td>9_lr=0.0050,n_epochs=500,n_hidden=8   </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00917767</td><td style=\"text-align: right;\">  0.00928359</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3500</td><td style=\"text-align: right;\">  0.718157</td><td style=\"text-align: right;\">  0.806815</td><td>True               </td><td style=\"text-align: right;\">             57.3237</td><td style=\"text-align: right;\">           57.3237</td><td style=\"text-align: right;\">       57.3237</td><td style=\"text-align: right;\"> 1671198854</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00009</td><td style=\"text-align: right;\">    0.0156081</td></tr>\n",
       "<tr><td>train_be744_00010</td><td>2022-12-16_10-54-18</td><td>True  </td><td>                </td><td>7fd1ec8b55384e28872f7c76ab57aa0c</td><td>10_lr=0.0100,n_epochs=500,n_hidden=8  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00949374</td><td style=\"text-align: right;\">  0.00981559</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 5720</td><td style=\"text-align: right;\">  0.686772</td><td style=\"text-align: right;\">  0.795744</td><td>True               </td><td style=\"text-align: right;\">             60.8468</td><td style=\"text-align: right;\">           60.8468</td><td style=\"text-align: right;\">       60.8468</td><td style=\"text-align: right;\"> 1671198858</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00010</td><td style=\"text-align: right;\">    0.0156271</td></tr>\n",
       "<tr><td>train_be744_00011</td><td>2022-12-16_10-55-02</td><td>True  </td><td>                </td><td>7284666db91d4b718a8947fc3d7df709</td><td>11_lr=0.0150,n_epochs=500,n_hidden=8  </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00986921</td><td style=\"text-align: right;\">  0.00872436</td><td>127.0.0.1</td><td style=\"text-align: right;\">  756</td><td style=\"text-align: right;\">  0.664446</td><td style=\"text-align: right;\">  0.818452</td><td>True               </td><td style=\"text-align: right;\">             60.1519</td><td style=\"text-align: right;\">           60.1519</td><td style=\"text-align: right;\">       60.1519</td><td style=\"text-align: right;\"> 1671198902</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00011</td><td style=\"text-align: right;\">    0.0156147</td></tr>\n",
       "<tr><td>train_be744_00012</td><td>2022-12-16_10-56-25</td><td>True  </td><td>                </td><td>50c2d66cbadd40ee9ccf7b2bbb2c9bb7</td><td>12_lr=0.0050,n_epochs=1000,n_hidden=8 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00825787</td><td style=\"text-align: right;\">  0.0105826 </td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3500</td><td style=\"text-align: right;\">  0.708986</td><td style=\"text-align: right;\">  0.779783</td><td>True               </td><td style=\"text-align: right;\">            129.955 </td><td style=\"text-align: right;\">          129.955 </td><td style=\"text-align: right;\">      129.955 </td><td style=\"text-align: right;\"> 1671198985</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00012</td><td style=\"text-align: right;\">    0.0156081</td></tr>\n",
       "<tr><td>train_be744_00013</td><td>2022-12-16_10-56-29</td><td>True  </td><td>                </td><td>7fd1ec8b55384e28872f7c76ab57aa0c</td><td>13_lr=0.0100,n_epochs=1000,n_hidden=8 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00880297</td><td style=\"text-align: right;\">  0.0114622 </td><td>127.0.0.1</td><td style=\"text-align: right;\"> 5720</td><td style=\"text-align: right;\">  0.706976</td><td style=\"text-align: right;\">  0.76148 </td><td>True               </td><td style=\"text-align: right;\">            130.581 </td><td style=\"text-align: right;\">          130.581 </td><td style=\"text-align: right;\">      130.581 </td><td style=\"text-align: right;\"> 1671198989</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00013</td><td style=\"text-align: right;\">    0.0156271</td></tr>\n",
       "<tr><td>train_be744_00014</td><td>2022-12-16_10-56-25</td><td>True  </td><td>                </td><td>1d398e6110e54e1d91969ce7424d88b4</td><td>14_lr=0.0150,n_epochs=1000,n_hidden=8 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00868041</td><td style=\"text-align: right;\">  0.00864942</td><td>127.0.0.1</td><td style=\"text-align: right;\">12944</td><td style=\"text-align: right;\">  0.575121</td><td style=\"text-align: right;\">  0.820012</td><td>True               </td><td style=\"text-align: right;\">            123.947 </td><td style=\"text-align: right;\">          123.947 </td><td style=\"text-align: right;\">      123.947 </td><td style=\"text-align: right;\"> 1671198985</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00014</td><td style=\"text-align: right;\">    0.0156269</td></tr>\n",
       "<tr><td>train_be744_00015</td><td>2022-12-16_10-57-48</td><td>True  </td><td>                </td><td>725f5d20811b4072b253eb4b374015ad</td><td>15_lr=0.0050,n_epochs=1500,n_hidden=8 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00934356</td><td style=\"text-align: right;\">  0.0101373 </td><td>127.0.0.1</td><td style=\"text-align: right;\">14252</td><td style=\"text-align: right;\">  0.419729</td><td style=\"text-align: right;\">  0.789051</td><td>True               </td><td style=\"text-align: right;\">            189.137 </td><td style=\"text-align: right;\">          189.137 </td><td style=\"text-align: right;\">      189.137 </td><td style=\"text-align: right;\"> 1671199068</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00015</td><td style=\"text-align: right;\">    0.015625 </td></tr>\n",
       "<tr><td>train_be744_00016</td><td>2022-12-16_10-58-12</td><td>True  </td><td>                </td><td>7284666db91d4b718a8947fc3d7df709</td><td>16_lr=0.0100,n_epochs=1500,n_hidden=8 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00940884</td><td style=\"text-align: right;\">  0.0102152 </td><td>127.0.0.1</td><td style=\"text-align: right;\">  756</td><td style=\"text-align: right;\">  0.709179</td><td style=\"text-align: right;\">  0.78743 </td><td>True               </td><td style=\"text-align: right;\">            189.321 </td><td style=\"text-align: right;\">          189.321 </td><td style=\"text-align: right;\">      189.321 </td><td style=\"text-align: right;\"> 1671199092</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00016</td><td style=\"text-align: right;\">    0.0156147</td></tr>\n",
       "<tr><td>train_be744_00017</td><td>2022-12-16_10-59-11</td><td>True  </td><td>                </td><td>c81df167ca754430b8add20d282b0d4a</td><td>17_lr=0.0150,n_epochs=1500,n_hidden=8 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.0102294 </td><td style=\"text-align: right;\">  0.010396  </td><td>127.0.0.1</td><td style=\"text-align: right;\"> 5032</td><td style=\"text-align: right;\">  0.601442</td><td style=\"text-align: right;\">  0.783667</td><td>True               </td><td style=\"text-align: right;\">            182.22  </td><td style=\"text-align: right;\">          182.22  </td><td style=\"text-align: right;\">      182.22  </td><td style=\"text-align: right;\"> 1671199151</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00017</td><td style=\"text-align: right;\">    0.0156186</td></tr>\n",
       "<tr><td>train_be744_00018</td><td>2022-12-16_10-57-18</td><td>True  </td><td>                </td><td>5a68b6b5002e40e78a04a2a6e8617e80</td><td>18_lr=0.0050,n_epochs=500,n_hidden=10 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00863194</td><td style=\"text-align: right;\">  0.00893627</td><td>127.0.0.1</td><td style=\"text-align: right;\">13380</td><td style=\"text-align: right;\">  0.715514</td><td style=\"text-align: right;\">  0.814043</td><td>True               </td><td style=\"text-align: right;\">             59.6732</td><td style=\"text-align: right;\">           59.6732</td><td style=\"text-align: right;\">       59.6732</td><td style=\"text-align: right;\"> 1671199038</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00018</td><td style=\"text-align: right;\">    0        </td></tr>\n",
       "<tr><td>train_be744_00019</td><td>2022-12-16_10-57-30</td><td>True  </td><td>                </td><td>50c2d66cbadd40ee9ccf7b2bbb2c9bb7</td><td>19_lr=0.0100,n_epochs=500,n_hidden=10 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00934981</td><td style=\"text-align: right;\">  0.00963631</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3500</td><td style=\"text-align: right;\">  0.663212</td><td style=\"text-align: right;\">  0.799475</td><td>True               </td><td style=\"text-align: right;\">             64.5724</td><td style=\"text-align: right;\">           64.5724</td><td style=\"text-align: right;\">       64.5724</td><td style=\"text-align: right;\"> 1671199050</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00019</td><td style=\"text-align: right;\">    0.0156081</td></tr>\n",
       "<tr><td>train_be744_00020</td><td>2022-12-16_10-57-25</td><td>True  </td><td>                </td><td>1d398e6110e54e1d91969ce7424d88b4</td><td>20_lr=0.0150,n_epochs=500,n_hidden=10 </td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.009472  </td><td style=\"text-align: right;\">  0.0128445 </td><td>127.0.0.1</td><td style=\"text-align: right;\">12944</td><td style=\"text-align: right;\">  0.613933</td><td style=\"text-align: right;\">  0.732715</td><td>True               </td><td style=\"text-align: right;\">             59.12  </td><td style=\"text-align: right;\">           59.12  </td><td style=\"text-align: right;\">       59.12  </td><td style=\"text-align: right;\"> 1671199045</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00020</td><td style=\"text-align: right;\">    0.0156269</td></tr>\n",
       "<tr><td>train_be744_00021</td><td>2022-12-16_10-58-37</td><td>True  </td><td>                </td><td>92616637421e4f1c8b1417b12a6d79ab</td><td>21_lr=0.0050,n_epochs=1000,n_hidden=10</td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00789656</td><td style=\"text-align: right;\">  0.00840953</td><td>127.0.0.1</td><td style=\"text-align: right;\">13560</td><td style=\"text-align: right;\">  0.710137</td><td style=\"text-align: right;\">  0.825004</td><td>True               </td><td style=\"text-align: right;\">            128.081 </td><td style=\"text-align: right;\">          128.081 </td><td style=\"text-align: right;\">      128.081 </td><td style=\"text-align: right;\"> 1671199117</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00021</td><td style=\"text-align: right;\">    0.0156238</td></tr>\n",
       "<tr><td>train_be744_00022</td><td>2022-12-16_10-58-37</td><td>True  </td><td>                </td><td>7fd1ec8b55384e28872f7c76ab57aa0c</td><td>22_lr=0.0100,n_epochs=1000,n_hidden=10</td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00854754</td><td style=\"text-align: right;\">  0.00903181</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 5720</td><td style=\"text-align: right;\">  0.656363</td><td style=\"text-align: right;\">  0.812054</td><td>True               </td><td style=\"text-align: right;\">            127.383 </td><td style=\"text-align: right;\">          127.383 </td><td style=\"text-align: right;\">      127.383 </td><td style=\"text-align: right;\"> 1671199117</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00022</td><td style=\"text-align: right;\">    0.0156271</td></tr>\n",
       "<tr><td>train_be744_00023</td><td>2022-12-16_10-59-16</td><td>True  </td><td>                </td><td>5a68b6b5002e40e78a04a2a6e8617e80</td><td>23_lr=0.0150,n_epochs=1000,n_hidden=10</td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.0083289 </td><td style=\"text-align: right;\">  0.0164187 </td><td>127.0.0.1</td><td style=\"text-align: right;\">13380</td><td style=\"text-align: right;\">  0.596126</td><td style=\"text-align: right;\">  0.658339</td><td>True               </td><td style=\"text-align: right;\">            117.719 </td><td style=\"text-align: right;\">          117.719 </td><td style=\"text-align: right;\">      117.719 </td><td style=\"text-align: right;\"> 1671199156</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00023</td><td style=\"text-align: right;\">    0        </td></tr>\n",
       "<tr><td>train_be744_00024</td><td>2022-12-16_10-59-57</td><td>True  </td><td>                </td><td>1d398e6110e54e1d91969ce7424d88b4</td><td>24_lr=0.0050,n_epochs=1500,n_hidden=10</td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00888146</td><td style=\"text-align: right;\">  0.0090082 </td><td>127.0.0.1</td><td style=\"text-align: right;\">12944</td><td style=\"text-align: right;\">  0.691925</td><td style=\"text-align: right;\">  0.812546</td><td>True               </td><td style=\"text-align: right;\">            151.756 </td><td style=\"text-align: right;\">          151.756 </td><td style=\"text-align: right;\">      151.756 </td><td style=\"text-align: right;\"> 1671199197</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00024</td><td style=\"text-align: right;\">    0.0156269</td></tr>\n",
       "<tr><td>train_be744_00025</td><td>2022-12-16_10-59-59</td><td>True  </td><td>                </td><td>50c2d66cbadd40ee9ccf7b2bbb2c9bb7</td><td>25_lr=0.0100,n_epochs=1500,n_hidden=10</td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.00986474</td><td style=\"text-align: right;\">  0.00923594</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3500</td><td style=\"text-align: right;\">  0.663007</td><td style=\"text-align: right;\">  0.807807</td><td>True               </td><td style=\"text-align: right;\">            149.356 </td><td style=\"text-align: right;\">          149.356 </td><td style=\"text-align: right;\">      149.356 </td><td style=\"text-align: right;\"> 1671199199</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00025</td><td style=\"text-align: right;\">    0.0156081</td></tr>\n",
       "<tr><td>train_be744_00026</td><td>2022-12-16_11-00-06</td><td>True  </td><td>                </td><td>725f5d20811b4072b253eb4b374015ad</td><td>26_lr=0.0150,n_epochs=1500,n_hidden=10</td><td>FCPC-24146</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  0.0105981 </td><td style=\"text-align: right;\">  0.012372  </td><td>127.0.0.1</td><td style=\"text-align: right;\">14252</td><td style=\"text-align: right;\">  0.661779</td><td style=\"text-align: right;\">  0.742547</td><td>True               </td><td style=\"text-align: right;\">            137.244 </td><td style=\"text-align: right;\">          137.244 </td><td style=\"text-align: right;\">      137.244 </td><td style=\"text-align: right;\"> 1671199206</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>be744_00026</td><td style=\"text-align: right;\">    0.015625 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 11:00:07,008\tINFO tune.py:777 -- Total run time: 516.55 seconds (515.96 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "tuner = tune.Tuner(train, param_space=config, tune_config=tune.TuneConfig(metric=\"r2_valid\", mode=\"max\"))\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "962c8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_model(best_result, test_x, test_y):\n",
    "    best_trained_model = Net(best_result.config[\"n_hidden\"])\n",
    "    \n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "        \n",
    "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        pred_y = best_trained_model(test_x)\n",
    "\n",
    "        loss_test = nn.MSELoss()(pred_y, test_y)\n",
    "        r2_test = r2_score(test_y, pred_y)\n",
    "        \n",
    "        \n",
    "    return {\"loss_test\":loss_test, \"r2_test\":r2_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37aff123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Melhores valores para os hiperparâmetros do modelo**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor para o hiperparâmetro 'n_hidden':  10\n",
      "Melhor valor para o hiperparâmetro 'n_epochs':  1000\n",
      "Melhor valor para o hiperparâmetro 'lr':  0.005\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Performance do modelo para dados de treinamento**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE obtido para esses valores de hiperparâmetros:  0.007896556479540923\n",
      "R2 obtido para esses valores de hiperparâmetros:  0.7101367653121752\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Performance do modelo para dados de validação**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE obtido para esses valores de hiperparâmetros:  0.00840953178703785\n",
      "R2 obtido para esses valores de hiperparâmetros:  0.8250035320174215\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Performance do modelo para dados de teste**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE obtido para esses valores de hiperparâmetros:  0.011851509101688862\n",
      "R2 obtido para esses valores de hiperparâmetros:  0.7134748889498002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "display(Markdown(\"**Melhores valores para os hiperparâmetros do modelo**\"))\n",
    "print(\"Melhor valor para o hiperparâmetro 'n_hidden': \",results.get_best_result().config[\"n_hidden\"])\n",
    "print(\"Melhor valor para o hiperparâmetro 'n_epochs': \",results.get_best_result().config[\"n_epochs\"])\n",
    "print(\"Melhor valor para o hiperparâmetro 'lr': \",results.get_best_result().config[\"lr\"])\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "display(Markdown(\"**Performance do modelo para dados de treinamento**\"))\n",
    "print(\"MSE obtido para esses valores de hiperparâmetros: \",(results.get_best_result().metrics[\"loss_train\"]))\n",
    "print(\"R2 obtido para esses valores de hiperparâmetros: \",(results.get_best_result().metrics[\"r2_train\"]))\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "display(Markdown(\"**Performance do modelo para dados de validação**\"))\n",
    "print(\"MSE obtido para esses valores de hiperparâmetros: \",(results.get_best_result().metrics[\"loss_valid\"].item()))\n",
    "print(\"R2 obtido para esses valores de hiperparâmetros: \",(results.get_best_result().metrics[\"r2_valid\"]))\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "display(Markdown(\"**Performance do modelo para dados de teste**\"))\n",
    "results_best_model = evaluate_best_model(results.get_best_result(), tensor_x_test, tensor_y_test)\n",
    "print(\"MSE obtido para esses valores de hiperparâmetros: \",(results_best_model[\"loss_test\"].item()))\n",
    "print(\"R2 obtido para esses valores de hiperparâmetros: \",(results_best_model[\"r2_test\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87585d18",
   "metadata": {},
   "source": [
    "- Pode-se observar que o modelo explica 64.0% das amostras de treinamento e 73.8% das amostras de teste\n",
    "- Não há indícios de sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1906ea4",
   "metadata": {},
   "source": [
    "0.6802740060437853"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
